{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aC2jP39zAbhl"
   },
   "source": [
    "# Inference code for face detection algorthims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kIqhKGyQAuUf"
   },
   "source": [
    "Download test image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GY1JN9DBK5ZZ"
   },
   "outputs": [],
   "source": [
    "image_path = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "87MPZn7dAlps"
   },
   "source": [
    "## Haar Cascade - Viola-Jones Algorithm\n",
    "\n",
    "The Viola-Jones face detector proposed by researchers Paul Viola and Michael Jones in 2001 signaled one of the first major breakthroughs in this field.\n",
    "\n",
    "Employing the line or edge-detection features proposed in the Viola-Jones detector, Haar Cascades managed to provide the much-needed breakthrough in face detection. Though it significantly improved the speed and accuracy of the detections, it had its limitations and failed when called upon to detect faces in noisy images. Over the years, there have been many improvements. The Haar Cascade algorithm was used not only for Face Detection but also for Eye Detection, License Plate Detection etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u5vUpcXsU2LN"
   },
   "source": [
    "### Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o4gTLhjQVDDI"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cLZ4RqFTucBE"
   },
   "source": [
    "### Initializing the HaarCascade Face Detector\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eTx-o7LS00sy",
    "outputId": "d075c44f-2279-4762-ab07-06dfee3acf88"
   },
   "outputs": [],
   "source": [
    "# Download Cascade classifier file\n",
    "!wget \"https://raw.githubusercontent.com/opencv/opencv/master/data/haarcascades/haarcascade_frontalface_default.xml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fx6qBBiB8wzi"
   },
   "outputs": [],
   "source": [
    "# Initialize the cascade classifiers for face\n",
    "face_cascade = cv2.CascadeClassifier('haarcascade_frontalface_default.xml')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vl4dXXS0LfPt"
   },
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Gwq07LkoLhCP",
    "outputId": "69f0dd7a-bf3a-404b-add1-db48de5dc148"
   },
   "outputs": [],
   "source": [
    "# Read image\n",
    "img = cv2.imread(image_path)\n",
    "\n",
    "# Save time\n",
    "t0 = time.time()\n",
    "\n",
    "# Getting the detections\n",
    "detections = face_cascade.detectMultiScale(img, scaleFactor = 1.2, minNeighbors = 5)\n",
    "\n",
    "# Calculate inference time\n",
    "inf_time = round(time.time() - t0, 3)\n",
    "\n",
    "# Print results\n",
    "print(f\"Detections: {detections}\")\n",
    "print(f\"Inference time: {inf_time}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3Z_jI5-6LtBn"
   },
   "source": [
    "### Display Detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oclH2hbQZFHE"
   },
   "outputs": [],
   "source": [
    "# Draw detections\n",
    "if len(detections) > 0:\n",
    "    for face in detections:\n",
    "        cv2.rectangle(img,face,(0,255,0),5)\n",
    "\n",
    "# Write inference time\n",
    "img = cv2.putText(img, f\"Inf Time: {inf_time}s\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255), 3, cv2.LINE_AA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "CCgovwaxbpg3",
    "outputId": "1f264627-38ee-414e-c53a-72464266c5f1"
   },
   "outputs": [],
   "source": [
    "# Display image\n",
    "img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YAGeEJCQdb14"
   },
   "source": [
    "## Dlib-HOG\n",
    "\n",
    "A widely used Face Detector, Dlib uses the classical Histogram of Gradients (HoG) feature, combined with a linear classifier, an image pyramid and a sliding window detection scheme. Learn more about HoG in this post. It employs 5 HOG filters:\n",
    "\n",
    "1. front looking \n",
    "2. left looking \n",
    "3. right looking \n",
    "4. front looking, but rotated left \n",
    "5. front looking, but rotated right "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B58AXATpdb1-"
   },
   "source": [
    "### Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W9oodw4Udb1-"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import dlib\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fgw1Vv3pdb1-"
   },
   "source": [
    "### Initializing the Dlib Face Detector\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d8NUyuTzdb1_"
   },
   "outputs": [],
   "source": [
    "# Initializing the Dlib Face Detector\n",
    "detector = dlib.get_frontal_face_detector()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oRt7TOlDdb1_"
   },
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ryWjutkvdb1_",
    "outputId": "4a71f507-610b-407a-ba83-f21d5ff3e150"
   },
   "outputs": [],
   "source": [
    "# Read image\n",
    "img = cv2.imread(image_path)\n",
    "\n",
    "# Save time\n",
    "t0 = time.time()\n",
    "\n",
    "# Getting the detections\n",
    "detections = detector(img)\n",
    "\n",
    "# Calculate inference time\n",
    "inf_time = round(time.time() - t0, 3)\n",
    "\n",
    "# Print results\n",
    "print(f\"Detections: {detections}\")\n",
    "print(f\"Inference time: {inf_time}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8g2-CXXQdb1_"
   },
   "source": [
    "### Display Detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BlsuhZ8odb2A"
   },
   "outputs": [],
   "source": [
    "# Draw detections\n",
    "if len(detections) > 0:\n",
    "    for detection in detections:\n",
    "        # Converting predicted and ground truth bounding boxes to required format\n",
    "        pred_bbox = [detection.left(),detection.top(),detection.right()-detection.left(),detection.bottom()-detection.top()]\n",
    "        cv2.rectangle(img,pred_bbox,(0,255,0),5)\n",
    "\n",
    "# Write inference time\n",
    "img = cv2.putText(img, f\"Inf Time: {inf_time}s\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255), 3, cv2.LINE_AA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "BSTKsenpdb2A",
    "outputId": "0936be22-15b6-45b2-d215-ebebc6c6345c"
   },
   "outputs": [],
   "source": [
    "# Display image\n",
    "img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P_rx3RejjxQi"
   },
   "source": [
    "## SSD\n",
    "\n",
    "Single Shot detector the name of the model itself reveals most of the details about the model. Yes, the SSD model detects the object in a single pass over the input image, unlike other models, which traverse the image more than once to get an output detection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SXqhkEZUjxQn"
   },
   "source": [
    "### Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m0n7cN9jjxQn"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7k7Th1m-jxQn"
   },
   "source": [
    "### Initializing the SSD Face Detector\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eR4qfSmljxQo",
    "outputId": "da4e99b2-8d33-45a9-c4b3-e41c423fdf9e"
   },
   "outputs": [],
   "source": [
    "!wget \"https://github.com/spmallick/learnopencv/blob/master/FaceDetectionComparison/models/res10_300x300_ssd_iter_140000_fp16.caffemodel?raw=true\" -O res10_300x300_ssd_iter_140000_fp16.caffemodel\n",
    "!wget \"https://raw.githubusercontent.com/spmallick/learnopencv/master/FaceDetectionComparison/models/deploy.prototxt\" -O deploy.prototxt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t83e08iDm4J0"
   },
   "outputs": [],
   "source": [
    "detector = cv2.dnn.DetectionModel(\"res10_300x300_ssd_iter_140000_fp16.caffemodel\", \"deploy.prototxt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iemNEy9WjxQo"
   },
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U_TGoGV1jxQo",
    "outputId": "b90093b1-e6ed-4d21-d5bb-8749dce18870"
   },
   "outputs": [],
   "source": [
    "# Read image\n",
    "img = cv2.imread(image_path)\n",
    "\n",
    "# Save time\n",
    "t0 = time.time()\n",
    "\n",
    "# Getting the detections\n",
    "detections = detector.detect(img)\n",
    "\n",
    "# Calculate inference time\n",
    "inf_time = round(time.time() - t0, 3)\n",
    "\n",
    "# Print results\n",
    "print(f\"Detections: {detections}\")\n",
    "print(f\"Inference time: {inf_time}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KBKZ89trjxQo"
   },
   "source": [
    "### Display Detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uA3zvaBKjxQo"
   },
   "outputs": [],
   "source": [
    "# Draw detections\n",
    "if len(detections[2]) > 0:\n",
    "    for face in detections[2]:\n",
    "        cv2.rectangle(img,face,(0,255,0),5)\n",
    "\n",
    "# Write inference time\n",
    "img = cv2.putText(img, f\"Inf Time: {inf_time}s\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255), 3, cv2.LINE_AA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "7U_5lf5UjxQo",
    "outputId": "d6e43622-5f0e-4946-aead-59b2ccf731b1"
   },
   "outputs": [],
   "source": [
    "# Display image\n",
    "img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "apZYslzmogYY"
   },
   "source": [
    "## MTCNN\n",
    "\n",
    "A more recent model, MTCNN stands for Multi-Task Cascaded Convolutional Neural Network. Published in 2016 by Zhang et al., this commonly used model consists of neural networks connected in a cascade fashion. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iD_F3C9OogYZ"
   },
   "source": [
    "### Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sOxdCz-DogYZ"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DwGrtBWiogYZ"
   },
   "source": [
    "### Initializing the MTCNN Face Detector\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dyPmGPB5Lv5s",
    "outputId": "31d82ec5-1521-467e-ed0d-3c63b80ccdfd"
   },
   "outputs": [],
   "source": [
    "!pip install mtcnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2eneJDqRL0gi"
   },
   "outputs": [],
   "source": [
    "from mtcnn.mtcnn import MTCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bKU9BgpUL8Rq"
   },
   "outputs": [],
   "source": [
    "detector=MTCNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "78IBeqaLogYa"
   },
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2hJXN-1uogYa",
    "outputId": "8fb4a9de-9804-463a-e4fb-bafe88d16c5c"
   },
   "outputs": [],
   "source": [
    "# Read image\n",
    "img = cv2.imread(image_path)\n",
    "\n",
    "# Save time\n",
    "t0 = time.time()\n",
    "\n",
    "# Getting the detections\n",
    "detections = detector.detect_faces(img)\n",
    "\n",
    "# Calculate inference time\n",
    "inf_time = round(time.time() - t0, 3)\n",
    "\n",
    "# Print results\n",
    "print(f\"Detections: {detections}\")\n",
    "print(f\"Inference time: {inf_time}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zhL3bFUeogYa"
   },
   "source": [
    "### Display Detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KuytwrMDogYa"
   },
   "outputs": [],
   "source": [
    "# Draw detections\n",
    "if len(detections) > 0:\n",
    "    for detection in detections:\n",
    "        # Converting predicted and ground truth bounding boxes to required format\n",
    "        pred_bbox = detection['box']\n",
    "        # print(\"bbox:\", pred_bbox)\n",
    "        cv2.rectangle(img,pred_bbox,(0,255,0),5)\n",
    "\n",
    "# Write inference time\n",
    "img = cv2.putText(img, f\"Inf Time: {inf_time}s\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255), 3, cv2.LINE_AA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "wJTx3Fn3ogYa",
    "outputId": "0c85e04a-5034-45e5-f551-a60727d736ff"
   },
   "outputs": [],
   "source": [
    "# Display image\n",
    "img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yLZSTSKopdia"
   },
   "source": [
    "## DSFD\n",
    "\n",
    "Dual Shot Face Detector is a novel Face Detection approach that addresses the following three major aspects of Face Detection:\n",
    "\n",
    "1. Better feature learning\n",
    "2. Progressive loss design\n",
    "3. Anchor assign-based data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yy-FUNvQpdif"
   },
   "source": [
    "### Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QZ3dsEjgpdif"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n8Gnsk9BqKAM"
   },
   "source": [
    "### Installing DSFD Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f6jnp6gOTUxr",
    "outputId": "1a57342e-bd14-4366-efa6-5c628b87773d"
   },
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/hukkelas/DSFD-Pytorch-Inference.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lLr-YpUupdif"
   },
   "source": [
    "### Initializing the DSFD Face Detector\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TgdGJmv4q2FC"
   },
   "outputs": [],
   "source": [
    "import face_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156,
     "referenced_widgets": [
      "34d958c70d974d2f85c94843a8a07b75",
      "fc47e56e3e5f4eca96b0a64ab7716dc8",
      "579fb2582a48492585e7107e6e7f5896",
      "88d4382519ed40bcaf2415f1b3f7af15",
      "c9e54026262844cd8a91b2c078c4b323",
      "dacb075ebd0c47ddaa70d81dd8da2b96",
      "e07f6d9791ea445cab720a5a28db6850",
      "44c901803724430c934a4efcf867cc5a",
      "0677aa76c1d8470e8540ba5bf819a0ab",
      "b940d8d2a3c441d69223028ee2ed0dea",
      "0b519d71a0bb4d4f8908197351b881ea"
     ]
    },
    "id": "clRuC3syq5X3",
    "outputId": "0ec41d1e-eb25-4768-e9a5-547255794f65"
   },
   "outputs": [],
   "source": [
    "detector = face_detection.build_detector(\"DSFDDetector\", confidence_threshold=.5, nms_iou_threshold=.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bTYggKMvpdig"
   },
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PqwCN0uQpdig",
    "outputId": "653161a2-d6b7-4c91-ead0-77c2e4e2fc31"
   },
   "outputs": [],
   "source": [
    "# Read image\n",
    "img = cv2.imread(image_path)\n",
    "\n",
    "# Save time\n",
    "t0 = time.time()\n",
    "\n",
    "# Getting the detections\n",
    "detections = detector.detect(img)\n",
    "\n",
    "# Calculate inference time\n",
    "inf_time = round(time.time() - t0, 3)\n",
    "\n",
    "# Print results\n",
    "print(f\"Detections: {detections}\")\n",
    "print(f\"Inference time: {inf_time}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IGyxKx7cpdig"
   },
   "source": [
    "### Display Detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZkT99Ikmpdig"
   },
   "outputs": [],
   "source": [
    "# Draw detections\n",
    "if len(detections) > 0:\n",
    "    for detection in detections:\n",
    "        # Converting predicted and ground truth bounding boxes to required format\n",
    "        pred_bbox = detection\n",
    "\n",
    "        pred_bbox[2] = pred_bbox[2] - pred_bbox[0]\n",
    "        pred_bbox[3] = pred_bbox[3] - pred_bbox[1]\n",
    "\n",
    "        pred_bbox = [int(i) for i in pred_bbox[:4]]\n",
    "\n",
    "        cv2.rectangle(img,pred_bbox,(0,255,0),5)\n",
    "\n",
    "# Write inference time\n",
    "img = cv2.putText(img, f\"Inf Time: {inf_time}s\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255), 3, cv2.LINE_AA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "EbHSZQaFpdig",
    "outputId": "236eaa14-9ae6-45f5-d7c1-76f62cc6db32"
   },
   "outputs": [],
   "source": [
    "# Display image\n",
    "img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tnWC3DmMtTPy"
   },
   "source": [
    "## RetinaFace-MobileNetV1\n",
    "\n",
    "RetinaFace is a practical single-stage SOTA face detector that was initially introduced in the arXiv technical report and then accepted by CVPR 2020. It is a part of the InsightFace project from DeepInsight, which is also credited with many more top Face-Recognition techniques like ArcFace, SubCenter ArcFace, PartialFC, and multiple facial applications too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WlB0FOxktTP4"
   },
   "source": [
    "### Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oT0bd8HltTP4"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DbMvntwutTP4"
   },
   "source": [
    "### Installing DSFD Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r27lE5nrtTP5",
    "outputId": "3c5a9d7e-cfe5-4657-c81a-c38211f54645"
   },
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/hukkelas/DSFD-Pytorch-Inference.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pxH3SyjxtTP5"
   },
   "source": [
    "### Initializing the RetinaNetMobileNetV1 Face Detector\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CYbBQ-pPtTP5"
   },
   "outputs": [],
   "source": [
    "import face_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "61c75a1504064e7c9e8774c020d4f93d",
      "f77c55b6be47471f9364e85947b08c7b",
      "66cb352bc85440548108eef60c41be1b",
      "9e5b86e601124cb3822202b6510f866c",
      "2ee442bd47cd431e9dc24f3adb78c914",
      "6665e46eebbf4efb9afb0ce991ec1470",
      "a0d6b999ecf64fef9fae13400e74c6a2",
      "667e27bb160540569a0f95008af5bf94",
      "68e06996185d4cc095f9f47a07d4a19e",
      "2ecca61456614a72b52aac5d235b3432",
      "7e8a36457f0f4ae8af7ce4a01455d2f6"
     ]
    },
    "id": "__e26pa8tTP5",
    "outputId": "d615e68d-a0e4-4030-f812-12da9c03528a"
   },
   "outputs": [],
   "source": [
    "detector = face_detection.build_detector(\"RetinaNetMobileNetV1\", confidence_threshold=.5, nms_iou_threshold=.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "noGNM7INtTP5"
   },
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_ai5xGqytTP5",
    "outputId": "17211b74-d550-4902-f356-12722aa674e4"
   },
   "outputs": [],
   "source": [
    "# Read image\n",
    "img = cv2.imread(image_path)\n",
    "\n",
    "# Save time\n",
    "t0 = time.time()\n",
    "\n",
    "# Getting the detections\n",
    "detections = detector.detect(img)\n",
    "\n",
    "# Calculate inference time\n",
    "inf_time = round(time.time() - t0, 3)\n",
    "\n",
    "# Print results\n",
    "print(f\"Detections: {detections}\")\n",
    "print(f\"Inference time: {inf_time}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0kDVtcWQtTP5"
   },
   "source": [
    "### Display Detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h6oMlUEotTP5"
   },
   "outputs": [],
   "source": [
    "# Draw detections\n",
    "if len(detections) > 0:\n",
    "    for detection in detections:\n",
    "        # Converting predicted and ground truth bounding boxes to required format\n",
    "        pred_bbox = detection\n",
    "\n",
    "        pred_bbox[2] = pred_bbox[2] - pred_bbox[0]\n",
    "        pred_bbox[3] = pred_bbox[3] - pred_bbox[1]\n",
    "\n",
    "        pred_bbox = [int(i) for i in pred_bbox[:4]]\n",
    "\n",
    "        cv2.rectangle(img,pred_bbox,(0,255,0),5)\n",
    "\n",
    "# Write inference time\n",
    "img = cv2.putText(img, f\"Inf Time: {inf_time}s\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255), 3, cv2.LINE_AA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "ZU2-kt_ltTP6",
    "outputId": "e273413b-d65e-4d46-8fb6-ad46ab8e3fa2"
   },
   "outputs": [],
   "source": [
    "# Display image\n",
    "img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-fa-HZBftrAK"
   },
   "source": [
    "## RetinaFace-ResNet50\n",
    "\n",
    "RetinaFace is a practical single-stage SOTA face detector that was initially introduced in the arXiv technical report and then accepted by CVPR 2020. It is a part of the InsightFace project from DeepInsight, which is also credited with many more top Face-Recognition techniques like ArcFace, SubCenter ArcFace, PartialFC, and multiple facial applications too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vx6LElEetrAK"
   },
   "source": [
    "### Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NHNQThSWtrAK"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jlvNI9JxtrAL"
   },
   "source": [
    "### Installing DSFD Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FRnljR7utrAL",
    "outputId": "a586215a-6490-46ec-b56b-6636f70e85ca"
   },
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/hukkelas/DSFD-Pytorch-Inference.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qNVyNA60trAL"
   },
   "source": [
    "### Initializing the RetinaNetResNet50 Face Detector\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "30zRM14RtrAL"
   },
   "outputs": [],
   "source": [
    "import face_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "6bc541e27e2942179b8848e0a9415cdd",
      "ff3c46658cf543138619d91825c2b76f",
      "69f2f62083804f2e999f8e453754ebd6",
      "e6cc8936c4734c869a8f6ef6872a298e",
      "6e03879ca2dd49afa27883230ebb017d",
      "e744fbe1988a443fb9a6142b2f9f09b9",
      "59fc2d1a9e88498c924d0c5607537598",
      "6c660ae5a87642e68f55dc2d748a4cd1",
      "88adb4854fd5446ab40764b7067ccf6c",
      "5d9dc6f46ac2459bbf7724e80a4a35e2",
      "036f0f4ca1004113853188e5ec284db7"
     ]
    },
    "id": "LrruQ2M8trAL",
    "outputId": "278ef72e-d7c6-410e-83d1-443307577f44"
   },
   "outputs": [],
   "source": [
    "detector = face_detection.build_detector(\"RetinaNetResNet50\", confidence_threshold=.5, nms_iou_threshold=.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "le2xJeOAtrAL"
   },
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "r9zaT7GVtrAL",
    "outputId": "986ad562-058b-4e38-91e7-ec6ed125a6a9"
   },
   "outputs": [],
   "source": [
    "# Read image\n",
    "img = cv2.imread(image_path)\n",
    "\n",
    "# Save time\n",
    "t0 = time.time()\n",
    "\n",
    "# Getting the detections\n",
    "detections = detector.detect(img)\n",
    "\n",
    "# Calculate inference time\n",
    "inf_time = round(time.time() - t0, 3)\n",
    "\n",
    "# Print results\n",
    "print(f\"Detections: {detections}\")\n",
    "print(f\"Inference time: {inf_time}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gw3YPxzltrAL"
   },
   "source": [
    "### Display Detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TBMLopSctrAL"
   },
   "outputs": [],
   "source": [
    "# Draw detections\n",
    "if len(detections) > 0:\n",
    "    for detection in detections:\n",
    "        # Converting predicted and ground truth bounding boxes to required format\n",
    "        pred_bbox = detection\n",
    "\n",
    "        pred_bbox[2] = pred_bbox[2] - pred_bbox[0]\n",
    "        pred_bbox[3] = pred_bbox[3] - pred_bbox[1]\n",
    "\n",
    "        pred_bbox = [int(i) for i in pred_bbox[:4]]\n",
    "\n",
    "        cv2.rectangle(img,pred_bbox,(0,255,0),5)\n",
    "\n",
    "# Write inference time\n",
    "img = cv2.putText(img, f\"Inf Time: {inf_time}s\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255), 3, cv2.LINE_AA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "fqTOOycxtrAL",
    "outputId": "8c1fa555-453d-4d44-f1a2-e7949894ea72"
   },
   "outputs": [],
   "source": [
    "# Display image\n",
    "img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "idl18thcuSpx"
   },
   "source": [
    "## MediaPipe\n",
    "\n",
    "A framework for building perception pipelines that perform inferences over arbitrary sensory data, MediaPipe includes images, video streams, as well as audio data. \n",
    "\n",
    "It can be used for rapid prototyping of perception pipelines with reusable components and in production-ready Machine Learning applications. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "51JFKL5uuSp2"
   },
   "source": [
    "### Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pxgcJTAnuSp3"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UL_a_pQ4uSp3"
   },
   "source": [
    "### Initializing the MediaPipe Face Detector\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lvqtDpJOuSp3",
    "outputId": "456c3438-c64c-471c-9de9-2a617ec53b0d"
   },
   "outputs": [],
   "source": [
    "!pip install mediapipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iJATJIH1uSp3"
   },
   "outputs": [],
   "source": [
    "import mediapipe as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jAOm7rSwuSp3"
   },
   "outputs": [],
   "source": [
    "mp_face_detection = mp.solutions.face_detection\n",
    "\n",
    "detector = mp_face_detection.FaceDetection(min_detection_confidence=0.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sGVjMFYKuSp3"
   },
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k5nQOSjKuSp3",
    "outputId": "36a01f50-a51f-428a-89dc-804ce5e31be1"
   },
   "outputs": [],
   "source": [
    "# Read image\n",
    "img = cv2.imread(image_path)\n",
    "\n",
    "# Save time\n",
    "t0 = time.time()\n",
    "\n",
    "# Getting the detections\n",
    "predictions = detector.process(img)\n",
    "\n",
    "# Calculate inference time\n",
    "inf_time = round(time.time() - t0, 3)\n",
    "\n",
    "# Print results\n",
    "print(f\"Detections: {predictions.detections}\")\n",
    "print(f\"Inference time: {inf_time}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rkvbx6HxuSp3"
   },
   "source": [
    "### Display Detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bt6uq9ApuSp3",
    "outputId": "0747695b-a1ac-4b22-8337-fe9109a93f46"
   },
   "outputs": [],
   "source": [
    "# Draw detections\n",
    "if predictions.detections:\n",
    "    for detection in predictions.detections:\n",
    "        # Converting predicted and ground truth bounding boxes to required format\n",
    "        img_W = int(img.shape[1])\n",
    "        img_H = int(img.shape[0])\n",
    "        pred_bbox = detection.location_data.relative_bounding_box\n",
    "        pred_bbox = [int(pred_bbox.xmin * img_W), int(pred_bbox.ymin * img_H), int(pred_bbox.width * img_W), int(pred_bbox.height * img_H)]\n",
    "        print(\"bbox:\", pred_bbox)\n",
    "        cv2.rectangle(img,pred_bbox,(0,255,0),5)\n",
    "\n",
    "# Write inference time\n",
    "img = cv2.putText(img, f\"Inf Time: {inf_time}s\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255), 3, cv2.LINE_AA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "-HgxQ9B5uSp3",
    "outputId": "196c3484-1fe9-434f-de66-6f67b477d5f3"
   },
   "outputs": [],
   "source": [
    "# Display image\n",
    "img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rMCfV2MFwSVA"
   },
   "source": [
    "## YuNet\n",
    "\n",
    "Traditionally OpenCV was equipped with the face detectors like Haar cascades and HOG detectors that worked well for frontal faces but failed otherwise. The recent release of OpenCV (4.5.4 Oct 2021) saw the addition of a face detection model called YuNet that solves this problem. \n",
    "\n",
    "It is a CNN-based face detector developed by Chengrui Wang and Yuantao Feng. It is a very lightweight and fast model. With a model size of less than an MB, it can be loaded on almost any device. It adopts mobilenet as its backbone and contains 85000 parameters in total. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9IiaLRoXwSVF"
   },
   "source": [
    "### Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-SoJF0llwSVF"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L6HEE9nAwSVF"
   },
   "source": [
    "### Initializing the YuNet Face Detector\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uni-88LtwSVF",
    "outputId": "8ead5317-50fa-4ada-a048-35c2468c2aa9"
   },
   "outputs": [],
   "source": [
    "!wget \"https://github.com/opencv/opencv_zoo/blob/master/models/face_detection_yunet/face_detection_yunet_2022mar.onnx?raw=true\" -O face_detection_yunet_2022mar.onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EOVSxbI2wSVG"
   },
   "outputs": [],
   "source": [
    "detector = cv2.FaceDetectorYN.create(\"face_detection_yunet_2022mar.onnx\", \"\", (320, 320))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nvkysWFIwSVG"
   },
   "source": [
    "### Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3VGAF3OHwSVG",
    "outputId": "ef07108b-7f61-4baf-bd1e-63e2902b6d09"
   },
   "outputs": [],
   "source": [
    "# Read image\n",
    "img = cv2.imread(image_path)\n",
    "\n",
    "# Get image dimensions\n",
    "img_W = int(img.shape[1])\n",
    "img_H = int(img.shape[0])\n",
    "\n",
    "# Save time\n",
    "t0 = time.time()\n",
    "\n",
    "# Getting the detections\n",
    "detector.setInputSize((img_W, img_H))\n",
    "detections = detector.detect(img)\n",
    "\n",
    "# Calculate inference time\n",
    "inf_time = round(time.time() - t0, 3)\n",
    "\n",
    "# Print results\n",
    "print(f\"Detections: {detections}\")\n",
    "print(f\"Inference time: {inf_time}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RWeOeWrjwSVG"
   },
   "source": [
    "### Display Detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B3f0emtSwSVG"
   },
   "outputs": [],
   "source": [
    "# Draw detections\n",
    "if (detections[1] is not None) and (len(detections[1]) > 0):\n",
    "    for detection in detections[1]:\n",
    "        # Converting predicted and ground truth bounding boxes to required format\n",
    "        pred_bbox = detection\n",
    "        pred_bbox = [int(i) for i in pred_bbox[:4]]\n",
    "\n",
    "        cv2.rectangle(img,pred_bbox,(0,255,0),5)\n",
    "\n",
    "# Write inference time\n",
    "img = cv2.putText(img, f\"Inf Time: {inf_time}s\", (10, 60), cv2.FONT_HERSHEY_SIMPLEX, 2, (0, 0, 255), 3, cv2.LINE_AA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 269
    },
    "id": "id9TgVDAwSVG",
    "outputId": "5c848dde-7509-4e6d-ee49-6af050bb0abb"
   },
   "outputs": [],
   "source": [
    "# Display image\n",
    "img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB)\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "036f0f4ca1004113853188e5ec284db7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "0677aa76c1d8470e8540ba5bf819a0ab": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "0b519d71a0bb4d4f8908197351b881ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "2ecca61456614a72b52aac5d235b3432": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "2ee442bd47cd431e9dc24f3adb78c914": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "34d958c70d974d2f85c94843a8a07b75": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fc47e56e3e5f4eca96b0a64ab7716dc8",
       "IPY_MODEL_579fb2582a48492585e7107e6e7f5896",
       "IPY_MODEL_88d4382519ed40bcaf2415f1b3f7af15"
      ],
      "layout": "IPY_MODEL_c9e54026262844cd8a91b2c078c4b323"
     }
    },
    "44c901803724430c934a4efcf867cc5a": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "579fb2582a48492585e7107e6e7f5896": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_44c901803724430c934a4efcf867cc5a",
      "max": 481004605,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_0677aa76c1d8470e8540ba5bf819a0ab",
      "value": 481004605
     }
    },
    "59fc2d1a9e88498c924d0c5607537598": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "5d9dc6f46ac2459bbf7724e80a4a35e2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "61c75a1504064e7c9e8774c020d4f93d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f77c55b6be47471f9364e85947b08c7b",
       "IPY_MODEL_66cb352bc85440548108eef60c41be1b",
       "IPY_MODEL_9e5b86e601124cb3822202b6510f866c"
      ],
      "layout": "IPY_MODEL_2ee442bd47cd431e9dc24f3adb78c914"
     }
    },
    "6665e46eebbf4efb9afb0ce991ec1470": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "667e27bb160540569a0f95008af5bf94": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "66cb352bc85440548108eef60c41be1b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_667e27bb160540569a0f95008af5bf94",
      "max": 1789735,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_68e06996185d4cc095f9f47a07d4a19e",
      "value": 1789735
     }
    },
    "68e06996185d4cc095f9f47a07d4a19e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "69f2f62083804f2e999f8e453754ebd6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6c660ae5a87642e68f55dc2d748a4cd1",
      "max": 109497761,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_88adb4854fd5446ab40764b7067ccf6c",
      "value": 109497761
     }
    },
    "6bc541e27e2942179b8848e0a9415cdd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ff3c46658cf543138619d91825c2b76f",
       "IPY_MODEL_69f2f62083804f2e999f8e453754ebd6",
       "IPY_MODEL_e6cc8936c4734c869a8f6ef6872a298e"
      ],
      "layout": "IPY_MODEL_6e03879ca2dd49afa27883230ebb017d"
     }
    },
    "6c660ae5a87642e68f55dc2d748a4cd1": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6e03879ca2dd49afa27883230ebb017d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7e8a36457f0f4ae8af7ce4a01455d2f6": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "88adb4854fd5446ab40764b7067ccf6c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "88d4382519ed40bcaf2415f1b3f7af15": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b940d8d2a3c441d69223028ee2ed0dea",
      "placeholder": "",
      "style": "IPY_MODEL_0b519d71a0bb4d4f8908197351b881ea",
      "value": " 459M/459M [00:21&lt;00:00, 23.4MB/s]"
     }
    },
    "9e5b86e601124cb3822202b6510f866c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2ecca61456614a72b52aac5d235b3432",
      "placeholder": "",
      "style": "IPY_MODEL_7e8a36457f0f4ae8af7ce4a01455d2f6",
      "value": " 1.71M/1.71M [00:00&lt;00:00, 2.03MB/s]"
     }
    },
    "a0d6b999ecf64fef9fae13400e74c6a2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b940d8d2a3c441d69223028ee2ed0dea": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c9e54026262844cd8a91b2c078c4b323": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "dacb075ebd0c47ddaa70d81dd8da2b96": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e07f6d9791ea445cab720a5a28db6850": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e6cc8936c4734c869a8f6ef6872a298e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5d9dc6f46ac2459bbf7724e80a4a35e2",
      "placeholder": "",
      "style": "IPY_MODEL_036f0f4ca1004113853188e5ec284db7",
      "value": " 104M/104M [00:06&lt;00:00, 21.1MB/s]"
     }
    },
    "e744fbe1988a443fb9a6142b2f9f09b9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f77c55b6be47471f9364e85947b08c7b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6665e46eebbf4efb9afb0ce991ec1470",
      "placeholder": "",
      "style": "IPY_MODEL_a0d6b999ecf64fef9fae13400e74c6a2",
      "value": "100%"
     }
    },
    "fc47e56e3e5f4eca96b0a64ab7716dc8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dacb075ebd0c47ddaa70d81dd8da2b96",
      "placeholder": "",
      "style": "IPY_MODEL_e07f6d9791ea445cab720a5a28db6850",
      "value": "100%"
     }
    },
    "ff3c46658cf543138619d91825c2b76f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e744fbe1988a443fb9a6142b2f9f09b9",
      "placeholder": "",
      "style": "IPY_MODEL_59fc2d1a9e88498c924d0c5607537598",
      "value": "100%"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
